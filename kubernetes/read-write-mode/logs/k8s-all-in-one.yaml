apiVersion: v1
kind: Namespace
metadata:
  name: logging-system
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki
  namespace: logging-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: alloy
    app.kubernetes.io/version: v1.0.0
    helm.sh/chart: alloy-0.1.1
  name: alloy
  namespace: monitoring-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir
  namespace: monitoring-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: alloy
    app.kubernetes.io/version: v1.0.0
    helm.sh/chart: alloy-0.1.1
  name: alloy
rules:
- apiGroups:
  - ""
  - discovery.k8s.io
  - networking.k8s.io
  resources:
  - endpoints
  - endpointslices
  - ingresses
  - nodes
  - nodes/proxy
  - nodes/metrics
  - pods
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - pods
  - pods/log
  - namespaces
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - monitoring.grafana.com
  resources:
  - podlogs
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - monitoring.coreos.com
  resources:
  - prometheusrules
  verbs:
  - get
  - list
  - watch
- nonResourceURLs:
  - /metrics
  verbs:
  - get
- apiGroups:
  - monitoring.coreos.com
  resources:
  - podmonitors
  - servicemonitors
  - probes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - replicasets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - replicasets
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-clusterrole
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  verbs:
  - get
  - watch
  - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: alloy
    app.kubernetes.io/version: v1.0.0
    helm.sh/chart: alloy-0.1.1
  name: alloy
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: alloy
subjects:
- kind: ServiceAccount
  name: alloy
  namespace: monitoring-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-clusterrolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: loki-clusterrole
subjects:
- kind: ServiceAccount
  name: loki
  namespace: logging-system
---
apiVersion: v1
data:
  LOKI_COMPACTOR_HOST: loki-backend.logging-system.svc.cluster.local
  LOKI_DISTRIBUTOR_HOST: loki-write.logging-system.svc.cluster.local
  LOKI_INGESTER_HOST: loki-write.logging-system.svc.cluster.local
  LOKI_QUERIER_HOST: loki-read.logging-system.svc.cluster.local
  LOKI_QUERY_FRONTEND_HOST: loki-read.logging-system.svc.cluster.local
  LOKI_QUERY_SCHEDULER_HOST: loki-read.logging-system.svc.cluster.local
  LOKI_RULER_HOST: loki-backend.logging-system.svc.cluster.local
kind: ConfigMap
metadata:
  name: nginx-env
  namespace: gateway
---
apiVersion: v1
data:
  config.yaml: |2

    auth_enabled: false

    # -reporting.enabled=false
    analytics:
     reporting_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9095
      log_level: info
      log_format: json

    # https://grafana.com/docs/loki/latest/configure/#use-environment-variables-in-the-configuration
    common:
      compactor_address: http://loki-backend.logging-system.svc.cluster.local:3100
      path_prefix: /var/loki
      replication_factor: 1
      storage:
        s3:
          bucketnames: loki-data
          endpoint: ${LOKI_S3_ENDPOINT:-minio.minio-system.svc.cluster.local:443}
          access_key_id: ${LOKI_S3_ACCESS_KEY_ID:-lgtmp}
          secret_access_key: ${LOKI_S3_SECRET_ACCESS_KEY:-supersecret}
          insecure: ${LOKI_S3_INSECURE:-false}
          s3forcepathstyle: true
          http_config:
            insecure_skip_verify: true

    bloom_gateway:
      enabled: true
      client:
        addresses: "dns+loki-backend.logging-system.svc.cluster.local:9095"
        cache_results: true
        results_cache:
          cache:
            memcached_client:
              addresses: "dns+memcached.memcached-system.svc.cluster.local:11211"

    bloom_compactor:
      enabled: true
      ring:
        kvstore:
          store: memberlist

    frontend:
      scheduler_address: query-scheduler-discovery.logging-system.svc.cluster.local:9095
      tail_proxy_url: http://loki-querier.logging-system.svc.cluster.local:3100
    frontend_worker:
      scheduler_address: query-scheduler-discovery.logging-system.svc.cluster.local:9095

    index_gateway:
      mode: simple

    compactor:
      working_directory: /tmp/compactor

    memberlist:
      join_members:
      - loki-memberlist.logging-system.svc.cluster.local:7946

    query_range:
      align_queries_with_step: true

      cache_results: true
      results_cache:
        cache:
          memcached_client:
            addresses: "dns+memcached.memcached-system.svc.cluster.local:11211"

      cache_index_stats_results: true
      index_stats_results_cache:
        cache:
          memcached_client:
            addresses: "dns+memcached.memcached-system.svc.cluster.local:11211"

    pattern_ingester:
      enabled: true

    limits_config:
      max_global_streams_per_user: 0
      ingestion_rate_mb: 50000
      ingestion_burst_size_mb: 50000
      volume_enabled: true

    ruler:
      storage:
        s3:
          bucketnames: loki-ruler
        type: s3

    runtime_config:
      file: /etc/loki/runtime-config/runtime-config.yaml

    schema_config:
      configs:
      - from: "2024-04-08"
        index:
          period: 24h
          prefix: loki_index_
        object_store: s3
        schema: v13
        store: tsdb

    storage_config:
      tsdb_shipper:
        active_index_directory: /var/loki/index
        cache_location: /var/loki/cache
        index_gateway_client:
          server_address: dns+loki-backend-headless.logging-system.svc.cluster.local:9095

    chunk_store_config:
      chunk_cache_config:
        memcached_client:
          addresses: "dns+memcached.memcached-system.svc.cluster.local:11211"
kind: ConfigMap
metadata:
  name: loki-config-t6t4f6hhcg
  namespace: logging-system
---
apiVersion: v1
data:
  runtime-config.yaml: |
    # This file can be used to set overrides or other runtime config.
    overrides:
      "fake": # limits for anonymous that the whole cluster enforces
        ingestion_rate_mb: 1500000
        max_streams_per_user: 100000
        max_chunks_per_query: 100000
      "anonymous": # limits for anonymous that the whole cluster enforces
        ingestion_rate_mb: 1500000
        max_streams_per_user: 100000
        max_chunks_per_query: 100000
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-runtime
  namespace: logging-system
---
apiVersion: v1
data:
  config.alloy: "logging {\n\tlevel  = coalesce(env(\"ALLOY_LOG_LEVEL\"), \"info\")\n\tformat
    = \"logfmt\"\n}\n\n/********************************************\n * Grafana LGTMP
    Stack Receiver Provider\n ********************************************/\nimport.git
    \"provider\" {\n\trepository     = \"https://github.com/qclaogui/codelab-monitoring.git\"\n\trevision
    \      = \"main\"\n\tpath           = \"alloy-modules/provider\"\n\tpull_frequency
    = \"24h\"\n}\n\nprovider.self_hosted_stack \"kubernetes\" {\n\tmetrics_endpoint_url
    = coalesce(env(\"SELF_HOSTED_METRICS_ENDPOINT_URL\"), \"http://nginx.gateway.svc:8080/api/v1/push\")\n\tlogs_endpoint_url
    \   = coalesce(env(\"SELF_HOSTED_LOGS_ENDPOINT_URL\"), \"http://nginx.gateway.svc:3100/loki/api/v1/push\")\n}\n\n/********************************************\n
    * Logs\n ********************************************/\nimport.file \"logs\" {\n\tfilename
    = coalesce(env(\"ALLOY_MODULES_FOLDER\"), \"/etc/alloy/modules\") + \"/kubernetes/logs\"\n}\n\nlogs.annotations_scrape
    \"kubernetes\" {\n\tannotation_prefix = \"logs.grafana.com\"\n\tforward_to        =
    [logs.keep_labels.kubernetes.receiver]\n}\n\nlogs.keep_labels \"kubernetes\" {\n\tforward_to
    = [provider.self_hosted_stack.kubernetes.logs_receiver]\n}\n\n/********************************************\n
    * Metrics\n ********************************************/\nimport.file \"metrics\"
    {\n\tfilename = coalesce(env(\"ALLOY_MODULES_FOLDER\"), \"/etc/alloy/modules\")
    + \"/kubernetes/metrics\"\n}\n\nmetrics.integrations_scrape \"kubernetes\" {\n\tforward_to
    = [provider.self_hosted_stack.kubernetes.metrics_receiver]\n}\n\nmetrics.podmonitors_scrape
    \"kubernetes\" {\n\tforward_to = [provider.self_hosted_stack.kubernetes.metrics_receiver]\n}\n\nmetrics.servicemonitors_scrape
    \"kubernetes\" {\n\tforward_to = [provider.self_hosted_stack.kubernetes.metrics_receiver]\n}\n"
kind: ConfigMap
metadata:
  name: alloy-config-8t9d8htff7
  namespace: monitoring-system
---
apiVersion: v1
data:
  k8s-events.alloy: "/*\nModule Components: component_cluster_events\n*/\n\ndeclare
    \"component_cluster_events\" {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment = \"Must be a list(LogsReceiver) where collected
    logs should be forwarded to\"\n\t}\n\n\targument \"job_label\" {\n\t\toptional
    = true\n\t\tdefault  = \"integrations/kubernetes/eventhandler\"\n\t}\n\n\targument
    \"cluster\" {\n\t\toptional = true\n\t\tdefault  = \"k3d\"\n\t}\n\n\tloki.source.kubernetes_events
    \"cluster_events\" {\n\t\tjob_name   = argument.job_label.value\n\t\tlog_format
    = \"logfmt\"\n\t\tforward_to = [loki.process.logs_service.receiver]\n\t}\n\n\tloki.process
    \"logs_service\" {\n\t\tstage.static_labels {\n\t\t\tvalues = {\n\t\t\t\tcluster
    = argument.cluster.value,\n\t\t\t}\n\t\t}\n\t\tforward_to = argument.forward_to.value\n\t}\n\n\t//
    // Logs Service\n\t// remote.kubernetes.secret \"logs_service\" {\n\t// \tname
    \     = \"loki-k8s-monitoring\"\n\t// \tnamespace = \"k8s-monitoring\"\n\t// }\n\t//
    // Loki\n\t// loki.write \"logs_service\" {\n\t// \tendpoint {\n\t// \t\turl       =
    nonsensitive(remote.kubernetes.secret.logs_service.data[\"host\"]) + \"/loki/api/v1/push\"\n\t//
    \t\ttenant_id = nonsensitive(remote.kubernetes.secret.logs_service.data[\"tenantId\"])\n\n\t//
    \t\tbasic_auth {\n\t// \t\t\tusername = nonsensitive(remote.kubernetes.secret.logs_service.data[\"username\"])\n\t//
    \t\t\tpassword = remote.kubernetes.secret.logs_service.data[\"password\"]\n\t//
    \t\t}\n\t// \t}\n\t// }\n}\n"
  memcached.alloy: "/*\nModule Components: component_memcached\n*/\n\ndeclare \"component_memcached\"
    {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment = \"Must be a list(MetricssReceiver) where collected
    metrics should be forwarded to\"\n\t}\n\n\targument \"job_label\" {\n\t\toptional
    = true\n\t\tdefault  = \"integrations/kubernetes/memcached\"\n\t}\n\n\targument
    \"memcached_address\" {\n\t\toptional = true\n\t\tdefault  = \"memcached:11211\"\n\t}\n\n\targument
    \"memcached_timeout\" {\n\t\toptional = true\n\t\tdefault  = \"5s\"\n\t}\n\n\targument
    \"instance_name\" {\n\t\tcomment  = \"instance of the Memcached\"\n\t\toptional
    = true\n\t}\n\n\targument \"keep_metrics\" {\n\t\toptional = true\n\t\tdefault
    \ = \"(up|memcached_commands_total|memcached_connections_total|memcached_current_bytes|memcached_current_connections|memcached_current_items|memcached_items_evicted_total|memcached_items_total|memcached_max_connections|memcached_read_bytes_total|memcached_up|memcached_uptime_seconds|memcached_version|memcached_written_bytes_total)\"\n\t}\n\n\targument
    \"scrape_interval\" {\n\t\tcomment  = \"How often to scrape metrics from the targets
    (default: 60s)\"\n\t\toptional = true\n\t\tdefault  = \"60s\"\n\t}\n\n\targument
    \"scrape_timeout\" {\n\t\tcomment  = \"How long before a scrape times out (default:
    10s)\"\n\t\toptional = true\n\t\tdefault  = \"10s\"\n\t}\n\n\t/***************************************************************\n\t*
    Integrations Memcached\n\t****************************************************************/\n\t//
    https://grafana.com/docs/alloy/latest/reference/components/prometheus.exporter.memcached/\n\tprometheus.exporter.memcached
    \"integrations_memcached_exporter\" {\n\t\taddress = argument.memcached_address.value\n\t\ttimeout
    = argument.memcached_timeout.value\n\t}\n\n\t/***************************************************************\n\t*
    Discovery Relabelings (pre-scrape)\n\t****************************************************************/\n\tdiscovery.relabel
    \"integrations_memcached_exporter\" {\n\t\ttargets = prometheus.exporter.memcached.integrations_memcached_exporter.targets\n\n\t\trule
    {\n\t\t\ttarget_label = \"job\"\n\t\t\treplacement  = argument.job_label.value\n\t\t}\n\n\t\trule
    {\n\t\t\ttarget_label = \"instance\"\n\t\t\treplacement  = coalesce(argument.instance_name.value,
    constants.hostname)\n\t\t}\n\t}\n\n\t/***************************************************************\n\t*
    Prometheus Scrape Integrations Targets\n\t****************************************************************/\n\tprometheus.scrape
    \"integrations_memcached_exporter\" {\n\t\ttargets = concat(\n\t\t\tdiscovery.relabel.integrations_memcached_exporter.output,\n\t\t)\n\n\t\tenable_protobuf_negotiation
    = true\n\t\tscrape_classic_histograms   = true\n\n\t\tscrape_interval = argument.scrape_interval.value\n\t\tscrape_timeout
    \ = argument.scrape_timeout.value\n\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\tforward_to
    = [prometheus.relabel.integrations_memcached_exporter.receiver]\n\t}\n\n\t/***************************************************************\n\t*
    Prometheus Metric Relabelings (post-scrape)\n\t****************************************************************/\n\tprometheus.relabel
    \"integrations_memcached_exporter\" {\n\t\tforward_to = argument.forward_to.value\n\n\t\t//
    keep only metrics that match the keep_metrics regex\n\t\trule {\n\t\t\tsource_labels
    = [\"__name__\"]\n\t\t\tregex         = argument.keep_metrics.value\n\t\t\taction
    \       = \"keep\"\n\t\t}\n\t}\n}\n"
  mysql.alloy: "/*\nModule Components: component_mysql\n*/\n\ndeclare \"component_mysql\"
    {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment = \"Must be a list(MetricssReceiver) where collected
    metrics should be forwarded to\"\n\t}\n\n\targument \"job_label\" {\n\t\toptional
    = true\n\t\tdefault  = \"integrations/kubernetes/mysql\"\n\t}\n\n\targument \"namespace\"
    {\n\t\toptional = true\n\t\tdefault  = \"monitoring-system\"\n\t}\n\n\targument
    \"name\" {\n\t\toptional = true\n\t\tdefault  = \"alloy-integrations-mysql\"\n\t}\n\n\targument
    \"instance_name\" {\n\t\toptional = true\n\t}\n\n\targument \"keep_metrics\" {\n\t\toptional
    = true\n\t\tdefault  = \"(up|instance:mysql_heartbeat_lag_seconds|instance:mysql_slave_lag_seconds|mysql_global_status_aborted_clients|mysql_global_status_aborted_connects|mysql_global_status_buffer_pool_pages|mysql_global_status_bytes_received|mysql_global_status_bytes_sent|mysql_global_status_commands_total|mysql_global_status_created_tmp_disk_tables|mysql_global_status_created_tmp_files|mysql_global_status_created_tmp_tables|mysql_global_status_handlers_total|mysql_global_status_innodb_log_waits|mysql_global_status_innodb_mem_adaptive_hash|mysql_global_status_innodb_mem_dictionary|mysql_global_status_innodb_num_open_files|mysql_global_status_innodb_page_size|mysql_global_status_max_used_connections|mysql_global_status_open_files|mysql_global_status_open_table_definitions|mysql_global_status_open_tables|mysql_global_status_opened_files|mysql_global_status_opened_table_definitions|mysql_global_status_opened_tables|mysql_global_status_qcache_free_memory|mysql_global_status_qcache_hits|mysql_global_status_qcache_inserts|mysql_global_status_qcache_lowmem_prunes|mysql_global_status_qcache_not_cached|mysql_global_status_qcache_queries_in_cache|mysql_global_status_queries|mysql_global_status_questions|mysql_global_status_select_full_join|mysql_global_status_select_full_range_join|mysql_global_status_select_range|mysql_global_status_select_range_check|mysql_global_status_select_scan|mysql_global_status_slow_queries|mysql_global_status_sort_merge_passes|mysql_global_status_sort_range|mysql_global_status_sort_rows|mysql_global_status_sort_scan|mysql_global_status_table_locks_immediate|mysql_global_status_table_locks_waited|mysql_global_status_table_open_cache_hits|mysql_global_status_table_open_cache_misses|mysql_global_status_table_open_cache_overflows|mysql_global_status_threads_cached|mysql_global_status_threads_connected|mysql_global_status_threads_created|mysql_global_status_threads_running|mysql_global_status_uptime|mysql_global_status_wsrep_local_recv_queue|mysql_global_status_wsrep_local_state|mysql_global_status_wsrep_ready|mysql_global_variables_innodb_additional_mem_pool_size|mysql_global_variables_innodb_buffer_pool_size|mysql_global_variables_innodb_log_buffer_size|mysql_global_variables_key_buffer_size|mysql_global_variables_max_connections|mysql_global_variables_open_files_limit|mysql_global_variables_query_cache_size|mysql_global_variables_table_definition_cache|mysql_global_variables_table_open_cache|mysql_global_variables_thread_cache_size|mysql_global_variables_tokudb_cache_size|mysql_global_variables_wsrep_desync|mysql_heartbeat_now_timestamp_seconds|mysql_heartbeat_stored_timestamp_seconds|mysql_info_schema_processlist_threads|mysql_slave_status_seconds_behind_master|mysql_slave_status_slave_io_running|mysql_slave_status_slave_sql_running|mysql_slave_status_sql_delay|mysql_up)\"\n\t}\n\n\targument
    \"scrape_interval\" {\n\t\tcomment  = \"How often to scrape metrics from the targets
    (default: 60s)\"\n\t\toptional = true\n\t\tdefault  = \"60s\"\n\t}\n\n\targument
    \"scrape_timeout\" {\n\t\tcomment  = \"How long before a scrape times out (default:
    10s)\"\n\t\toptional = true\n\t\tdefault  = \"10s\"\n\t}\n\n\tremote.kubernetes.secret
    \"mysql\" {\n\t\tname      = argument.name.value\n\t\tnamespace = argument.namespace.value\n\t}\n\n\t/***************************************************************\n\t*
    Integrations Mysql\n\t****************************************************************/\n\tprometheus.exporter.mysql
    \"integrations_mysqld_exporter\" {\n\t\tdata_source_name = nonsensitive(remote.kubernetes.secret.mysql.data[\"mysql-username\"])
    + \":\" + nonsensitive(remote.kubernetes.secret.mysql.data[\"mysql-password\"])
    + \"@(\" + nonsensitive(remote.kubernetes.secret.mysql.data[\"mysql-host\"]) +
    \")/\"\n\t}\n\n\t/***************************************************************\n\t*
    Discovery Relabelings (pre-scrape)\n\t****************************************************************/\n\tdiscovery.relabel
    \"integrations_mysqld_exporter\" {\n\t\ttargets = prometheus.exporter.mysql.integrations_mysqld_exporter.targets\n\n\t\trule
    {\n\t\t\ttarget_label = \"job\"\n\t\t\treplacement  = argument.job_label.value\n\t\t}\n\n\t\trule
    {\n\t\t\ttarget_label = \"instance\"\n\t\t\treplacement  = coalesce(argument.instance_name.value,
    constants.hostname)\n\t\t}\n\t}\n\n\t/***************************************************************\n\t*
    Prometheus Scrape Integrations Targets\n\t****************************************************************/\n\tprometheus.scrape
    \"integrations_mysqld_exporter\" {\n\t\ttargets = concat(\n\t\t\tdiscovery.relabel.integrations_mysqld_exporter.output,\n\t\t)\n\n\t\tenable_protobuf_negotiation
    = true\n\t\tscrape_classic_histograms   = true\n\n\t\tscrape_interval = argument.scrape_interval.value\n\t\tscrape_timeout
    \ = argument.scrape_timeout.value\n\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\tforward_to
    = [prometheus.relabel.integrations_mysqld_exporter.receiver]\n\t}\n\n\t/***************************************************************\n\t*
    Prometheus Metric Relabelings (post-scrape)\n\t****************************************************************/\n\tprometheus.relabel
    \"integrations_mysqld_exporter\" {\n\t\tforward_to = argument.forward_to.value\n\n\t\t//
    keep only metrics that match the keep_metrics regex\n\t\trule {\n\t\t\tsource_labels
    = [\"__name__\"]\n\t\t\tregex         = argument.keep_metrics.value\n\t\t\taction
    \       = \"keep\"\n\t\t}\n\t}\n}\n"
  redis.alloy: "/*\nModule Components: component_redis_exporter\n*/\n\ndeclare \"component_redis_exporter\"
    {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment = \"Must be a list(MetricssReceiver) where collected
    metrics should be forwarded to\"\n\t}\n\n\targument \"job_label\" {\n\t\toptional
    = true\n\t\tdefault  = \"integrations/kubernetes/redis_exporter\"\n\t}\n\n\targument
    \"namespace\" {\n\t\toptional = true\n\t\tdefault  = \"monitoring-system\"\n\t}\n\n\targument
    \"name\" {\n\t\toptional = true\n\t\tdefault  = \"alloy-integrations-redis\"\n\t}\n\n\targument
    \"instance_name\" {\n\t\toptional = true\n\t}\n\n\targument \"keep_metrics\" {\n\t\toptional
    = true\n\t\tdefault  = \"(up|redis_blocked_clients|redis_cluster_slots_fail|redis_cluster_slots_pfail|redis_cluster_state|redis_commands_duration_seconds_total|redis_commands_total|redis_connected_clients|redis_connected_slaves|redis_db_keys|redis_db_keys_expiring|redis_evicted_keys_total|redis_keyspace_hits_total|redis_keyspace_misses_total|redis_master_last_io_seconds_ago|redis_memory_fragmentation_ratio|redis_memory_max_bytes|redis_memory_used_bytes|redis_memory_used_rss_bytes|redis_total_system_memory_bytes|redis_up)\"\n\t}\n\n\targument
    \"scrape_interval\" {\n\t\tcomment  = \"How often to scrape metrics from the targets
    (default: 60s)\"\n\t\toptional = true\n\t\tdefault  = \"60s\"\n\t}\n\n\targument
    \"scrape_timeout\" {\n\t\tcomment  = \"How long before a scrape times out (default:
    10s)\"\n\t\toptional = true\n\t\tdefault  = \"10s\"\n\t}\n\n\tremote.kubernetes.secret
    \"redis\" {\n\t\tname      = argument.name.value\n\t\tnamespace = argument.namespace.value\n\t}\n\n\t/***************************************************************\n\t*
    Integrations Redis\n\t****************************************************************/\n\tprometheus.exporter.redis
    \"integrations_redis_exporter\" {\n\t\tredis_addr     = nonsensitive(remote.kubernetes.secret.redis.data[\"redis-addr\"])\n\t\tredis_password
    = nonsensitive(remote.kubernetes.secret.redis.data[\"redis-password\"])\n\t}\n\n\t/***************************************************************\n\t*
    Discovery Relabelings (pre-scrape)\n\t****************************************************************/\n\tdiscovery.relabel
    \"integrations_redis_exporter\" {\n\t\ttargets = prometheus.exporter.memcached.integrations_redis_exporter.targets\n\n\t\trule
    {\n\t\t\ttarget_label = \"job\"\n\t\t\treplacement  = argument.job_label.value\n\t\t}\n\n\t\trule
    {\n\t\t\ttarget_label = \"instance\"\n\t\t\treplacement  = coalesce(argument.instance_name.value,
    constants.hostname)\n\t\t}\n\t}\n\n\t/***************************************************************\n\t*
    Prometheus Scrape Integrations Targets\n\t****************************************************************/\n\tprometheus.scrape
    \"integrations_redis_exporter\" {\n\t\ttargets = concat(\n\t\t\tdiscovery.relabel.integrations_redis_exporter.output,\n\t\t)\n\n\t\tenable_protobuf_negotiation
    = true\n\t\tscrape_classic_histograms   = true\n\n\t\tscrape_interval = argument.scrape_interval.value\n\t\tscrape_timeout
    \ = argument.scrape_timeout.value\n\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\tforward_to
    = [prometheus.relabel.integrations_redis_exporter.receiver]\n\t}\n\n\t/***************************************************************\n\t*
    Prometheus Metric Relabelings (post-scrape)\n\t****************************************************************/\n\tprometheus.relabel
    \"integrations_redis_exporter\" {\n\t\tforward_to = argument.forward_to.value\n\n\t\t//
    keep only metrics that match the keep_metrics regex\n\t\trule {\n\t\t\tsource_labels
    = [\"__name__\"]\n\t\t\tregex         = argument.keep_metrics.value\n\t\t\taction
    \       = \"keep\"\n\t\t}\n\t}\n}\n"
kind: ConfigMap
metadata:
  name: alloy-modules-kubernetes-integrations-2kb5k574d2
  namespace: monitoring-system
---
apiVersion: v1
data:
  annotations-scrape.alloy: "/*\nModule Components: annotations_scrape\nDescription:
    Scrapes targets for logs based on kubernetes Pod annotations\n\n  Annotations:\n
    \   logs.grafana.com/ingest: true\n    logs.grafana.com/tenant: \"primary\"\n*/\n\ndeclare
    \"annotations_scrape\" {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment = \"Must be a list(LogsReceiver) where collected
    logs should be forwarded to\"\n\t}\n\n\targument \"tenant\" {\n\t\tcomment  =
    \"The tenant to filter logs to.  This does not have to be the tenantId, this is
    the value to look for in the logs.agent.grafana.com/tenant annotation, and this
    can be a regex.\"\n\t\toptional = true\n\t\tdefault  = \".*\"\n\t}\n\n\t// arguments
    for kubernetes discovery\n\targument \"namespaces\" {\n\t\tcomment  = \"The namespaces
    to look for targets in (default: [\\\"kube-system\\\"] is all namespaces)\"\n\t\toptional
    = true\n\t}\n\n\targument \"annotation_prefix\" {\n\t\tcomment  = \"The annotation_prefix
    to use (default: logs.grafana.com)\"\n\t\tdefault  = \"logs.grafana.com\"\n\t\toptional
    = true\n\t}\n\n\targument \"__sd_annotation\" {\n\t\toptional = true\n\t\tcomment
    \ = \"The logic is used to transform the annotation argument into a valid label
    name by removing unsupported characters.\"\n\t\tdefault  = replace(replace(replace(coalesce(argument.annotation_prefix.value,
    \"logs.grafana.com\"), \".\", \"_\"), \"/\", \"_\"), \"-\", \"_\")\n\t}\n\n\t//
    find all pods\n\tdiscovery.kubernetes \"annotation_logs\" {\n\t\trole = \"pod\"\n\n\t\tnamespaces
    {\n\t\t\tnames = coalesce(argument.namespaces.value, [])\n\t\t}\n\t}\n\n\t// filter
    logs by kubernetes annotations\n\tdiscovery.relabel \"annotation_logs_filter\"
    {\n\t\ttargets = discovery.kubernetes.annotation_logs.targets\n\n\t\t// allow
    pods to declare their logs to be ingested or not, the default is true\n\t\t//
    \  i.e. logs.grafana.com/ingest: false\n\t\trule {\n\t\t\taction        = \"keep\"\n\t\t\tsource_labels
    = [\n\t\t\t\t\"__meta_kubernetes_pod_annotation_\" + argument.__sd_annotation.value
    + \"_scrape\",\n\t\t\t]\n\t\t\tregex = \"^(true|)$\"\n\t\t}\n\n\t\t// allow pods
    to declare what tenant their logs should be written to, the following annotation
    is supported:\n\t\t//   logs.grafana.com/tenant: \"primary\"\n\t\trule {\n\t\t\taction
    \       = \"keep\"\n\t\t\tsource_labels = [\n\t\t\t\t\"__meta_kubernetes_pod_annotation_\"
    + argument.__sd_annotation.value + \"_tenant\",\n\t\t\t]\n\t\t\tregex = \"^(\"
    + argument.tenant.value + \")$\"\n\t\t}\n\n\t\t// set the instance label as the
    name of the worker node the pod is on\n\t\trule {\n\t\t\taction        = \"replace\"\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_node_name\"]\n\t\t\ttarget_label  = \"instance\"\n\t\t}\n\n\t\t//
    set the namespace label\n\t\trule {\n\t\t\tsource_labels = [\"__meta_kubernetes_namespace\"]\n\t\t\ttarget_label
    \ = \"namespace\"\n\t\t}\n\n\t\t// set the pod label\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_name\"]\n\t\t\ttarget_label  = \"pod\"\n\t\t}\n\n\t\t//
    set the container label\n\t\trule {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_container_name\"]\n\t\t\ttarget_label
    \ = \"container\"\n\t\t}\n\n\t\t// set a workload label\n\t\trule {\n\t\t\tsource_labels
    = [\n\t\t\t\t\"__meta_kubernetes_pod_controller_kind\",\n\t\t\t\t\"__meta_kubernetes_pod_controller_name\",\n\t\t\t]\n\t\t\tseparator
    \   = \"/\"\n\t\t\ttarget_label = \"workload\"\n\t\t}\n\t\t// remove the hash
    from the ReplicaSet\n\t\trule {\n\t\t\tsource_labels = [\"workload\"]\n\t\t\tregex
    \        = \"(ReplicaSet/.+)-.+\"\n\t\t\ttarget_label  = \"workload\"\n\t\t}\n\n\t\t//
    set the app name if specified as metadata labels \"app:\" or \"app.kubernetes.io/name:\"
    or \"k8s-app:\"\n\t\trule {\n\t\t\taction        = \"replace\"\n\t\t\tsource_labels
    = [\n\t\t\t\t\"__meta_kubernetes_pod_label_app_kubernetes_io_name\",\n\t\t\t\t\"__meta_kubernetes_pod_label_k8s_app\",\n\t\t\t\t\"__meta_kubernetes_pod_label_app\",\n\t\t\t]\n\t\t\tseparator
    \   = \";\"\n\t\t\tregex        = \"^(?:;*)?([^;]+).*$\"\n\t\t\treplacement  =
    \"$1\"\n\t\t\ttarget_label = \"app\"\n\t\t}\n\n\t\t// set the component if specified
    as metadata labels \"component:\" or \"app.kubernetes.io/component:\" or \"k8s-component:\"\n\t\trule
    {\n\t\t\taction        = \"replace\"\n\t\t\tsource_labels = [\n\t\t\t\t\"__meta_kubernetes_pod_label_app_kubernetes_io_component\",\n\t\t\t\t\"__meta_kubernetes_pod_label_k8s_component\",\n\t\t\t\t\"__meta_kubernetes_pod_label_component\",\n\t\t\t]\n\t\t\tregex
    \       = \"^(?:;*)?([^;]+).*$\"\n\t\t\treplacement  = \"$1\"\n\t\t\ttarget_label
    = \"component\"\n\t\t}\n\n\t\t// set the version if specified as metadata labels
    \"version:\" or \"app.kubernetes.io/version:\" or \"app_version:\"\n\t\trule {\n\t\t\taction
    \       = \"replace\"\n\t\t\tsource_labels = [\n\t\t\t\t\"__meta_kubernetes_pod_label_app_kubernetes_io_version\",\n\t\t\t\t\"__meta_kubernetes_pod_label_version\",\n\t\t\t\t\"__meta_kubernetes_pod_label_app_version\",\n\t\t\t]\n\t\t\tregex
    \       = \"^(?:;*)?([^;]+).*$\"\n\t\t\treplacement  = \"$1\"\n\t\t\ttarget_label
    = \"version\"\n\t\t}\n\n\t\t// set a source label\n\t\trule {\n\t\t\taction       =
    \"replace\"\n\t\t\treplacement  = \"kubernetes\"\n\t\t\ttarget_label = \"source\"\n\t\t}\n\n\t\t//
    set the job label to be namespace / friendly pod name\n\t\trule {\n\t\t\taction
    \       = \"replace\"\n\t\t\tsource_labels = [\n\t\t\t\t\"workload\",\n\t\t\t\t\"__meta_kubernetes_namespace\",\n\t\t\t]\n\t\t\tregex
    \       = \".+\\\\/(.+);(.+)\"\n\t\t\treplacement  = \"$2/$1\"\n\t\t\ttarget_label
    = \"job\"\n\t\t}\n\n\t\t// make all labels on the pod available to the pipeline
    as labels,\n\t\t// they are omitted before write via labelallow unless explicitly
    set\n\t\trule {\n\t\t\taction = \"labelmap\"\n\t\t\tregex  = \"__meta_kubernetes_pod_label_(.+)\"\n\t\t}\n\n\t\t//
    make all annotations on the pod available to the pipeline as labels,\n\t\t// they
    are omitted before write via labelallow unless explicitly set\n\t\trule {\n\t\t\taction
    = \"labelmap\"\n\t\t\tregex  = \"__meta_kubernetes_pod_annotation_(.+)\"\n\t\t}\n\n\t\t//
    as a result of kubernetes service discovery for pods, all of the meta data information
    is exposed in labels\n\t\t// __meta_kubernetes_pod_*, including __meta_kubernetes_pod_container_id
    which can be used to determine what\n\t\t// the pods container runtime is, docker
    (docker://...) or containerd (containerd://...) this will inform us\n\t\t// which
    parsing stage to use.  However, any labels that begin with __* are not passed
    to loki.process\n\t\t// (pipeline) stages. Use a relabeling stage to set a label
    that can be used a LogQL selector in the stage\n\t\t// below so parsing can be
    automatically determined, then drop the label from the loki.process stage.\n\t\t//
    set the container runtime as a label\n\t\trule {\n\t\t\taction        = \"replace\"\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_id\"]\n\t\t\tregex         = \"^(\\\\w+):\\\\/\\\\/.+$\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t\ttarget_label  = \"tmp_container_runtime\"\n\t\t}\n\t}\n\n\tloki.source.kubernetes
    \"lsd_kubernetes_logs\" {\n\t\ttargets    = discovery.relabel.annotation_logs_filter.output\n\t\tforward_to
    = [loki.process.parse.receiver]\n\t}\n\n\t// parse the log based on the container
    runtime\n\tloki.process \"parse\" {\n\t\tforward_to = argument.forward_to.value\n\t\t/*******************************************************************************\n\t\t*
    \                        Container Runtime Parsing\n\t\t********************************************************************************/\n\t\t//
    if the label tmp_container_runtime from above is containerd parse using cri\n\t\tstage.match
    {\n\t\t\tselector = \"{tmp_container_runtime=\\\"containerd\\\"}\"\n\t\t\t// the
    cri processing stage extracts the following k/v pairs: log, stream, time, flags\n\t\t\tstage.cri
    { }\n\n\t\t\t// Set the extract flags and stream values as labels\n\t\t\tstage.labels
    {\n\t\t\t\tvalues = {\n\t\t\t\t\tflags  = \"\",\n\t\t\t\t\tstream = \"\",\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t//
    if the label tmp_container_runtime from above is docker parse using docker\n\t\tstage.match
    {\n\t\t\tselector = \"{tmp_container_runtime=\\\"docker\\\"}\"\n\t\t\t// the docker
    processing stage extracts the following k/v pairs: log, stream, time\n\t\t\tstage.docker
    { }\n\n\t\t\t// Set the extract stream value as a label\n\t\t\tstage.labels {\n\t\t\t\tvalues
    = {\n\t\t\t\t\tstream = \"\",\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// drop the temporary
    container runtime label as it is no longer needed\n\t\tstage.label_drop {\n\t\t\tvalues
    = [\"tmp_container_runtime\"]\n\t\t}\n\t}\n}\n"
  keep-labels.alloy: "/*\nModule Components: keep_labels\nDescription: Pre-defined
    set of labels to keep, this stage should always be in-place as the previous relabeing\n
    \            stages make every pod label and annotation a label in the pipeline,
    which we do not want created\n             in Loki as that would have extremely
    high-cardinality.\n*/\n\ndeclare \"keep_labels\" {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment = \"Must be a list(LogsReceiver) where collected
    logs should be forwarded to\"\n\t}\n\n\targument \"keep_labels\" {\n\t\toptional
    = true\n\t\tcomment  = \"List of labels to keep before the log message is written
    to Loki\"\n\t\tdefault  = [\n\t\t\t\"app\",\n\t\t\t\"cluster\",\n\t\t\t\"component\",\n\t\t\t\"container\",\n\t\t\t\"env\",\n\t\t\t\"job\",\n\t\t\t\"level\",\n\t\t\t\"namespace\",\n\t\t\t\"region\",\n\t\t\t\"service\",\n\t\t\t\"squad\",\n\t\t\t\"team\",\n\t\t\t\"workload\",\n\t\t]\n\t}\n\n\t/*****************************************************************\n\t*
    LOKI PROCESS\n\t*****************************************************************/\n\tloki.process
    \"keep_labels\" {\n\t\tforward_to = argument.forward_to.value\n\n\t\t/*\n\t\tAs
    all of the pod labels and annotations we transformed into labels in the previous
    relabelings to make\n\t\tthem available to the pipeline processing we need to
    ensure they are not automatically created in Loki.\n\t\tThis would result in an
    extremely high number of labels and values severely impacting query performance.\n\t\tNot
    every log has to contain these labels, but this list should reflect the set of
    labels that you want\n\t\tto explicitly allow.\n\t\t*/\n\t\tstage.label_keep {\n\t\t\tvalues
    = argument.keep_labels.value\n\t\t}\n\t}\n\n\t/*****************************************************************\n\t*
    EXPORTS\n\t*****************************************************************/\n\texport
    \"receiver\" {\n\t\tvalue = loki.process.keep_labels.receiver\n\t}\n}\n"
kind: ConfigMap
metadata:
  name: alloy-modules-kubernetes-logs-d7c756mt2f
  namespace: monitoring-system
---
apiVersion: v1
data:
  integrations-scrape.alloy: "/*\nModule Components: integrations_scrape\nDescription:
    Integrations Module Components Scrape\n\nNote: Every argument except for \"forward_to\"
    is optional, and does have a defined default value.  However, the values for these\n
    \     arguments are not defined using the default = \" ... \" argument syntax,
    but rather using the coalesce(argument.value, \" ... \").\n      This is because
    if the argument passed in from another consuming module is set to null, the default
    = \" ... \" syntax will\n      does not override the value passed in, where coalesce()
    will return the first non-null value.\n*/\n\ndeclare \"integrations_scrape\" {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment = \"Must be a list(MetricssReceiver) where collected
    metrics should be forwarded to\"\n\t}\n\n\targument \"name\" {\n\t\tcomment  =
    \"Name of the integrations config\"\n\t\toptional = true\n\t\tdefault  = \"alloy-integrations\"\n\t}\n\n\targument
    \"namespace\" {\n\t\tcomment  = \"Namespace of the integrations config\"\n\t\toptional
    = true\n\t\tdefault  = \"default\"\n\t}\n\n\t/*****************************************************************\n\t*
    Import Integrations Components\n\t*****************************************************************/\n\t//
    integrations components local files\n\timport.file \"integrations\" {\n\t\tfilename
    = coalesce(env(\"ALLOY_MODULES_FOLDER\"), \"/etc/alloy/modules\") + \"/kubernetes/integrations\"\n\t}\n\n\t//
    // integrations components kubernetes configmap\n\t// remote.kubernetes.configmap
    \"integrations\" {\n\t// \tname      = argument.name.value\n\t// \tnamespace =
    argument.namespace.value\n\t// }\n\t// import.string \"integrations\" {\n\t//
    \tcontent = remote.kubernetes.configmap.integrations.data[\"memcached.alloy\"]\n\t//
    }\n\n\t/*****************************************************************\n\t*
    Memcached Integrations\n\t*****************************************************************/\n\tintegrations.component_memcached
    \"primary\" {\n\t\tforward_to = argument.forward_to.value\n\n\t\tinstance_name
    \    = \"primary\"\n\t\tmemcached_address = \"memcached.memcached-system.svc.cluster.local:11211\"\n\t\tmemcached_timeout
    = \"5s\"\n\t}\n\n\t// /*****************************************************************\n\t//
    * Mysql Integrations\n\t// *****************************************************************/\n\t//
    integrations.component_mysql \"primary\" {\n\t// \tforward_to = argument.forward_to.value\n\n\t//
    \tinstance_name = \"primary\"\n\t// \tname          = \"alloy-integrations-mysql\"\n\t//
    \tnamespace     = \"monitoring-system\"\n\t// }\n}\n"
  podmonitors-scrape.alloy: "/*\nModule Components: podmonitors_scrape\nDescription:
    Scrapes targets for metrics based on prometheus.operator.podmonitors\n*/\n\ndeclare
    \"podmonitors_scrape\" {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment  = \"Must be a list(MetricssReceiver) where collected
    metrics should be forwarded to\"\n\t\toptional = false\n\t}\n\n\t/*****************************************************************\n\t*
    Kubernetes Auto Scrape PodMonitors\n\t*****************************************************************/\n\tprometheus.operator.podmonitors
    \"scrape\" {\n\t\tforward_to = argument.forward_to.value\n\n\t\tclustering {\n\t\t\tenabled
    = true\n\t\t}\n\n\t\t// selector {\n\t\t// \tmatch_expression {\n\t\t// \t\tkey
    \     = \"team\"\n\t\t// \t\toperator = \"In\"\n\t\t// \t\tvalues   = [\"team-infra\"]\n\t\t//
    \t}\n\t\t// }\n\t}\n}\n"
  servicemonitors-scrape.alloy: "/*\nModule Components: servicemonitors_scrape\nDescription:
    Scrapes targets for metrics based on prometheus.operator.servicemonitors\n*/\n\ndeclare
    \"servicemonitors_scrape\" {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment  = \"Must be a list(MetricssReceiver) where collected
    metrics should be forwarded to\"\n\t\toptional = false\n\t}\n\n\t/*****************************************************************\n\t*
    Kubernetes Auto Scrape ServiceMonitors\n\t*****************************************************************/\n\tprometheus.operator.servicemonitors
    \"scrape\" {\n\t\tforward_to = argument.forward_to.value\n\n\t\tclustering {\n\t\t\tenabled
    = true\n\t\t}\n\t}\n}\n"
kind: ConfigMap
metadata:
  name: alloy-modules-kubernetes-metrics-bgtb8d5hch
  namespace: monitoring-system
---
apiVersion: v1
data:
  annotations-scrape.alloy: "/*\nModule Components: annotations_scrape\nDescription:
    Scrapes targets for metrics based on kubernetes Pod annotations\n\n*/\n\ndeclare
    \"annotations_scrape\" {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"forward_to\" {\n\t\tcomment = \"Must be a list(ProfilessReceiver) where collected
    logs should be forwarded to\"\n\t}\n\n\tdiscovery.kubernetes \"pyroscope_kubernetes\"
    {\n\t\trole = \"pod\"\n\t}\n\n\t// The default scrape config allows to define
    annotations based scraping.\n\t//\n\t// For example the following annotations:\n\t//\n\t//
    ```\n\t// profiles.grafana.com/memory.scrape: \"true\"\n\t// profiles.grafana.com/memory.port:
    \"8080\"\n\t// profiles.grafana.com/cpu.scrape: \"true\"\n\t// profiles.grafana.com/cpu.port:
    \"8080\"\n\t// profiles.grafana.com/goroutine.scrape: \"true\"\n\t// profiles.grafana.com/goroutine.port:
    \"8080\"\n\t// ```\n\t//\n\t// will scrape the `memory`, `cpu` and `goroutine`
    profiles from the `8080` port of the pod.\n\t//\n\t// For more information see
    https://grafana.com/docs/phlare/latest/operators-guide/deploy-kubernetes/#optional-scrape-your-own-workloads-profiles\n\tdiscovery.relabel
    \"kubernetes_pods\" {\n\t\ttargets = concat(discovery.kubernetes.pyroscope_kubernetes.targets)\n\n\t\trule
    {\n\t\t\taction        = \"drop\"\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_phase\"]\n\t\t\tregex
    \        = \"Pending|Succeeded|Failed|Completed\"\n\t\t}\n\n\t\trule {\n\t\t\taction
    = \"labelmap\"\n\t\t\tregex  = \"__meta_kubernetes_pod_label_(.+)\"\n\t\t}\n\n\t\trule
    {\n\t\t\taction        = \"replace\"\n\t\t\tsource_labels = [\"__meta_kubernetes_namespace\"]\n\t\t\ttarget_label
    \ = \"namespace\"\n\t\t}\n\n\t\trule {\n\t\t\taction        = \"replace\"\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_name\"]\n\t\t\ttarget_label  = \"pod\"\n\t\t}\n\n\t\trule
    {\n\t\t\taction        = \"replace\"\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_container_name\"]\n\t\t\ttarget_label
    \ = \"container\"\n\t\t}\n\t}\n\n\tdiscovery.relabel \"kubernetes_pods_memory_default_name\"
    {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\tdiscovery.relabel
    \"kubernetes_pods_memory_custom_name\" {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name\"]\n\t\t\taction
    \       = \"drop\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name\"\n\t\t\taction
    \       = \"keepequal\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\t/*****************************************************************\n\t*
    Kubernetes Pyroscope Scrape Memory\n\t*****************************************************************/\n\tpyroscope.scrape
    \"pyroscope_scrape_memory\" {\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_memory_default_name.output, discovery.relabel.kubernetes_pods_memory_custom_name.output)\n\t\tforward_to
    = argument.forward_to.value\n\n\t\tprofiling_config {\n\t\t\tprofile.memory {\n\t\t\t\tenabled
    = true\n\t\t\t}\n\n\t\t\tprofile.process_cpu {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.goroutine
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.block {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.mutex {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.fgprof
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\t\t}\n\t}\n\n\tdiscovery.relabel \"kubernetes_pods_cpu_default_name\"
    {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\tdiscovery.relabel
    \"kubernetes_pods_cpu_custom_name\" {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name\"]\n\t\t\taction
    \       = \"drop\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name\"\n\t\t\taction
    \       = \"keepequal\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\t/*****************************************************************\n\t*
    Kubernetes Pyroscope Scrape CPU\n\t*****************************************************************/\n\tpyroscope.scrape
    \"pyroscope_scrape_cpu\" {\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_cpu_default_name.output, discovery.relabel.kubernetes_pods_cpu_custom_name.output)\n\t\tforward_to
    = argument.forward_to.value\n\n\t\tprofiling_config {\n\t\t\tprofile.memory {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.process_cpu {\n\t\t\t\tenabled = true\n\t\t\t}\n\n\t\t\tprofile.goroutine
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.block {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.mutex {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.fgprof
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\t\t}\n\t}\n\n\tdiscovery.relabel \"kubernetes_pods_goroutine_default_name\"
    {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\tdiscovery.relabel
    \"kubernetes_pods_goroutine_custom_name\" {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name\"]\n\t\t\taction
    \       = \"drop\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name\"\n\t\t\taction
    \       = \"keepequal\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\t/*****************************************************************\n\t*
    Kubernetes Pyroscope Scrape Goroutine\n\t*****************************************************************/\n\tpyroscope.scrape
    \"pyroscope_scrape_goroutine\" {\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_goroutine_default_name.output,
    discovery.relabel.kubernetes_pods_goroutine_custom_name.output)\n\t\tforward_to
    = argument.forward_to.value\n\n\t\tprofiling_config {\n\t\t\tprofile.memory {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.process_cpu {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.goroutine
    {\n\t\t\t\tenabled = true\n\t\t\t}\n\n\t\t\tprofile.block {\n\t\t\t\tenabled =
    false\n\t\t\t}\n\n\t\t\tprofile.mutex {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.fgprof
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\t\t}\n\t}\n\n\tdiscovery.relabel \"kubernetes_pods_block_default_name\"
    {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\tdiscovery.relabel
    \"kubernetes_pods_block_custom_name\" {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name\"]\n\t\t\taction
    \       = \"drop\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name\"\n\t\t\taction
    \       = \"keepequal\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\t/*****************************************************************\n\t*
    Kubernetes Pyroscope Scrape Block\n\t*****************************************************************/\n\tpyroscope.scrape
    \"pyroscope_scrape_block\" {\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_block_default_name.output, discovery.relabel.kubernetes_pods_block_custom_name.output)\n\t\tforward_to
    = argument.forward_to.value\n\n\t\tprofiling_config {\n\t\t\tprofile.memory {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.process_cpu {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.goroutine
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.block {\n\t\t\t\tenabled
    = true\n\t\t\t}\n\n\t\t\tprofile.mutex {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.fgprof
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\t\t}\n\t}\n\n\tdiscovery.relabel \"kubernetes_pods_mutex_default_name\"
    {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\tdiscovery.relabel
    \"kubernetes_pods_mutex_custom_name\" {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name\"]\n\t\t\taction
    \       = \"drop\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name\"\n\t\t\taction
    \       = \"keepequal\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\t/*****************************************************************\n\t*
    Kubernetes Pyroscope Scrape Mutex\n\t*****************************************************************/\n\tpyroscope.scrape
    \"pyroscope_scrape_mutex\" {\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_mutex_default_name.output, discovery.relabel.kubernetes_pods_mutex_custom_name.output)\n\t\tforward_to
    = argument.forward_to.value\n\n\t\tprofiling_config {\n\t\t\tprofile.memory {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.process_cpu {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.goroutine
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.block {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.mutex {\n\t\t\t\tenabled = true\n\t\t\t}\n\n\t\t\tprofile.fgprof
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\t\t}\n\t}\n\n\tdiscovery.relabel \"kubernetes_pods_fgprof_default_name\"
    {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\tdiscovery.relabel
    \"kubernetes_pods_fgprof_custom_name\" {\n\t\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\t\trule
    {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scrape\"]\n\t\t\taction
    \       = \"keep\"\n\t\t\tregex         = \"true\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name\"]\n\t\t\taction
    \       = \"drop\"\n\t\t\tregex         = \"\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name\"\n\t\t\taction
    \       = \"keepequal\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scheme\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(https?)\"\n\t\t\ttarget_label
    \ = \"__scheme__\"\n\t\t\treplacement   = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_path\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+)\"\n\t\t\ttarget_label  = \"__profile_path__\"\n\t\t\treplacement
    \  = \"$1\"\n\t\t}\n\n\t\trule {\n\t\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port\"]\n\t\t\taction
    \       = \"replace\"\n\t\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\t\ttarget_label
    \ = \"__address__\"\n\t\t\treplacement   = \"$1:$2\"\n\t\t}\n\t}\n\n\t/*****************************************************************\n\t*
    Kubernetes Pyroscope Scrape Fgprof\n\t*****************************************************************/\n\tpyroscope.scrape
    \"pyroscope_scrape_fgprof\" {\n\t\tclustering {\n\t\t\tenabled = true\n\t\t}\n\n\t\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_fgprof_default_name.output, discovery.relabel.kubernetes_pods_fgprof_custom_name.output)\n\t\tforward_to
    = argument.forward_to.value\n\n\t\tprofiling_config {\n\t\t\tprofile.memory {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.process_cpu {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.goroutine
    {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.block {\n\t\t\t\tenabled
    = false\n\t\t\t}\n\n\t\t\tprofile.mutex {\n\t\t\t\tenabled = false\n\t\t\t}\n\n\t\t\tprofile.fgprof
    {\n\t\t\t\tenabled = true\n\t\t\t}\n\t\t}\n\t}\n}\n"
kind: ConfigMap
metadata:
  name: alloy-modules-kubernetes-profiles-66c27bc84g
  namespace: monitoring-system
---
apiVersion: v1
data:
  process-and-transform.alloy: "/*\nModule Components: process_and_transform\n\nDescription:
    Traces data collection processing and transformation\n*/\n\n// Processing And
    Transformation\ndeclare \"process_and_transform\" {\n\n\t/*****************************************************************\n\t*
    ARGUMENTS\n\t*****************************************************************/\n\targument
    \"traces_forward_to\" {\n\t\tcomment = \"Must be a list(TracesReceiver) where
    collected traces should be forwarded to\"\n\t}\n\n\targument \"logs_forward_to\"
    {\n\t\tcomment = \"Must be a list(LogsReceiver) where collected logs should be
    forwarded to\"\n\t}\n\n\targument \"metrics_forward_to\" {\n\t\tcomment = \"Must
    be a list(MetricsReceiver) where collected metrics should be forwarded to\"\n\t}\n\n\targument
    \"cluster\" {\n\t\toptional = true\n\t\tdefault  = \"k3d-k3s-codelab\"\n\t}\n\n\targument
    \"otlp_http_endpoint\" {\n\t\toptional = true\n\t\tdefault  = \"0.0.0.0:4318\"\n\t}\n\n\targument
    \"otlp_grpc_endpoint\" {\n\t\toptional = true\n\t\tdefault  = \"0.0.0.0:4317\"\n\t}\n\n\t/*****************************************************************\n\t*
    Jaeger for Metrics Logs Traces\n\t*****************************************************************/\n\totelcol.receiver.jaeger
    \"default\" {\n\t\tprotocols {\n\t\t\tgrpc {\n\t\t\t\tendpoint = \"0.0.0.0:14250\"\n\t\t\t}\n\n\t\t\tthrift_http
    {\n\t\t\t\tendpoint = \"0.0.0.0:14268\"\n\t\t\t}\n\n\t\t\tthrift_binary {\n\t\t\t\tendpoint
    = \"0.0.0.0:6832\"\n\t\t\t}\n\n\t\t\tthrift_compact {\n\t\t\t\tendpoint = \"0.0.0.0:6831\"\n\t\t\t}\n\t\t}\n\n\t\toutput
    {\n\t\t\tmetrics = [otelcol.processor.batch.default.input]\n\t\t\tlogs    = [otelcol.processor.resourcedetection.default.input]\n\t\t\ttraces
    \ = [otelcol.processor.resourcedetection.default.input]\n\t\t}\n\t}\n\n\t/*****************************************************************\n\t*
    Otelcol for Metrics Logs Traces\n\t*****************************************************************/\n\totelcol.receiver.otlp
    \"default\" {\n\t\tgrpc {\n\t\t\tendpoint = argument.otlp_grpc_endpoint.value\n\t\t}\n\n\t\thttp
    {\n\t\t\tendpoint = argument.otlp_http_endpoint.value\n\t\t}\n\n\t\toutput {\n\t\t\tmetrics
    = [otelcol.processor.batch.default.input]\n\t\t\tlogs    = [otelcol.processor.resourcedetection.default.input]\n\t\t\ttraces
    \ = [\n\t\t\t\totelcol.processor.resourcedetection.default.input,\n\t\t\t\totelcol.connector.spanlogs.autologging.input,\n\t\t\t]\n\t\t}\n\t}\n\n\totelcol.processor.resourcedetection
    \"default\" {\n\t\tdetectors = [\"env\"]\n\n\t\toutput {\n\t\t\tlogs   = [otelcol.processor.k8sattributes.default.input]\n\t\t\ttraces
    = [otelcol.processor.k8sattributes.default.input]\n\t\t}\n\t}\n\n\totelcol.processor.k8sattributes
    \"default\" {\n\t\textract {\n\t\t\tmetadata = [\n\t\t\t\t\"k8s.namespace.name\",\n\t\t\t\t\"k8s.pod.name\",\n\t\t\t\t\"k8s.deployment.name\",\n\t\t\t\t\"k8s.statefulset.name\",\n\t\t\t\t\"k8s.daemonset.name\",\n\t\t\t\t\"k8s.cronjob.name\",\n\t\t\t\t\"k8s.job.name\",\n\t\t\t\t\"k8s.node.name\",\n\t\t\t\t\"k8s.pod.uid\",\n\t\t\t\t\"k8s.pod.start_time\",\n\t\t\t]\n\t\t}\n\n\t\tpod_association
    {\n\t\t\tsource {\n\t\t\t\tfrom = \"connection\"\n\t\t\t}\n\t\t}\n\n\t\toutput
    {\n\t\t\tlogs   = [otelcol.processor.transform.add_resource_attributes.input]\n\t\t\ttraces
    = [otelcol.processor.transform.add_resource_attributes.input]\n\t\t}\n\t}\n\n\totelcol.processor.transform
    \"add_resource_attributes\" {\n\t\terror_mode = \"ignore\"\n\n\t\tlog_statements
    {\n\t\t\tcontext    = \"resource\"\n\t\t\tstatements = [\n\t\t\t\t`set(attributes[\"pod\"],
    attributes[\"k8s.pod.name\"])`,\n\t\t\t\t`set(attributes[\"namespace\"], attributes[\"k8s.namespace.name\"])`,\n\t\t\t\t`set(attributes[\"loki.resource.labels\"],
    \"pod, namespace, cluster, job\")`,\n\t\t\t\t`set(attributes[\"k8s.cluster.name\"],
    \"k3d-k3s-codelab\") where attributes[\"k8s.cluster.name\"] == nil`,\n\t\t\t]\n\t\t}\n\n\t\ttrace_statements
    {\n\t\t\tcontext    = \"resource\"\n\t\t\tstatements = [\n\t\t\t\t`set(attributes[\"k8s.cluster.name\"],
    \"k3d-k3s-codelab\") where attributes[\"k8s.cluster.name\"] == nil`,\n\t\t\t]\n\t\t}\n\n\t\toutput
    {\n\t\t\tlogs   = [otelcol.processor.filter.default.input]\n\t\t\ttraces = [otelcol.processor.filter.default.input]\n\t\t}\n\t}\n\n\totelcol.processor.filter
    \"default\" {\n\t\terror_mode = \"ignore\"\n\n\t\toutput {\n\t\t\tlogs   = [otelcol.processor.batch.default.input]\n\t\t\ttraces
    = [otelcol.processor.batch.default.input]\n\t\t}\n\t}\n\n\totelcol.processor.batch
    \"default\" {\n\t\tsend_batch_size     = 16384\n\t\tsend_batch_max_size = 0\n\t\ttimeout
    \            = \"5s\"\n\n\t\toutput {\n\t\t\tmetrics = [otelcol.processor.memory_limiter.default.input]\n\t\t\tlogs
    \   = [otelcol.processor.memory_limiter.default.input]\n\t\t\ttraces  = [otelcol.processor.memory_limiter.default.input]\n\t\t}\n\t}\n\n\totelcol.processor.memory_limiter
    \"default\" {\n\t\tcheck_interval         = \"1s\"\n\t\tlimit_percentage       =
    50\n\t\tspike_limit_percentage = 30\n\n\t\toutput {\n\t\t\tmetrics = [otelcol.exporter.prometheus.tracesmetrics.input]\n\t\t\tlogs
    \   = [otelcol.exporter.loki.traceslogs.input]\n\t\t\ttraces  = argument.traces_forward_to.value\n\t\t}\n\t}\n\n\totelcol.exporter.prometheus
    \"tracesmetrics\" {\n\t\tforward_to = argument.metrics_forward_to.value\n\t}\n\n\totelcol.exporter.loki
    \"traceslogs\" {\n\t\tforward_to = [loki.process.traceslogs.receiver]\n\t}\n\n\t//
    The OpenTelemetry spanlog connector processes incoming trace spans and extracts
    data from them ready\n\t// for logging.\n\totelcol.connector.spanlogs \"autologging\"
    {\n\t\t// We only want to output a line for each root span (ie. every single trace),
    and not for every\n\t\t// process or span (outputting a line for every span would
    be extremely verbose).\n\t\tspans     = false\n\t\troots     = true\n\t\tprocesses
    = false\n\n\t\t// We want to ensure that the following three span attributes are
    included in the log line, if present.\n\t\tspan_attributes = [\n\t\t\t\"http.method\",\n\t\t\t\"http.target\",\n\t\t\t\"http.status_code\",\n\t\t]\n\n\t\t//
    Overrides the default key in the log line to be `traceId`, which is then used
    by Grafana to\n\t\t// identify the trace ID for correlation with the Tempo datasource.\n\t\toverrides
    {\n\t\t\ttrace_id_key = \"traceId\"\n\t\t}\n\n\t\t// Send to the OpenTelemetry
    Loki exporter.\n\t\toutput {\n\t\t\tlogs = [otelcol.exporter.loki.autologging.input]\n\t\t}\n\t}\n\n\t//
    Simply forwards the incoming OpenTelemetry log format out as a Loki log.\n\t//
    We need this stage to ensure we can then process the logline as a Loki object.\n\totelcol.exporter.loki
    \"autologging\" {\n\t\tforward_to = [loki.process.autologging.receiver]\n\t}\n\n\t//
    The Loki processor allows us to accept a correctly formatted Loki log and mutate
    it into\n\t// a set of fields for output.\n\tloki.process \"autologging\" {\n\t\t//
    The JSON stage simply extracts the `body` (the actual logline) from the Loki log,
    ignoring\n\t\t// all other fields.\n\t\tstage.json {\n\t\t\texpressions = {\"body\"
    = \"\"}\n\t\t}\n\t\t// The output stage takes the body (the main logline) and
    uses this as the source for the output\n\t\t// logline. In this case, it essentially
    turns it into logfmt.\n\t\tstage.output {\n\t\t\tsource = \"body\"\n\t\t}\n\n\t\tforward_to
    = [loki.process.traceslogs.receiver]\n\t}\n\n\tloki.process \"traceslogs\" {\n\t\tstage.tenant
    {\n\t\t\tvalue = \"anonymous\"\n\t\t}\n\n\t\tforward_to = argument.logs_forward_to.value\n\t}\n\n\t/*****************************************************************\n\t*
    EXPORTS\n\t*****************************************************************/\n\texport
    \"alloy_traces_input\" {\n\t\tvalue = otelcol.processor.batch.default.input\n\t}\n}\n"
kind: ConfigMap
metadata:
  name: alloy-modules-kubernetes-traces-8mgm8th9m5
  namespace: monitoring-system
---
apiVersion: v1
data:
  alertmanager_fallback_config.yaml: |
    route:
      group_wait: 0s
      receiver: empty-receiver

    receivers:
      # In this example we're not going to send any notification out of Alertmanager.
      - name: 'empty-receiver'
  mimir.yaml: |
    # Do not use this configuration in production.
    # It is for demonstration purposes only.
    multitenancy_enabled: false

    # -usage-stats.enabled=false
    usage_stats:
      enabled: false

    server:
      http_listen_port: 8080
      grpc_listen_port: 9095
      log_level: info

    # https://grafana.com/docs/mimir/latest/references/configuration-parameters/#use-environment-variables-in-the-configuration
    common:
      storage:
        backend: s3
        s3:
          endpoint:          ${MIMIR_S3_ENDPOINT:minio.minio-system.svc:443}
          access_key_id:     ${MIMIR_S3_ACCESS_KEY_ID:lgtmp}
          secret_access_key: ${MIMIR_S3_SECRET_ACCESS_KEY:supersecret}
          insecure:          ${MIMIR_S3_INSECURE:false}
          http:
            insecure_skip_verify: true

    alertmanager:
      data_dir: /data/alertmanager
      enable_api: true
      external_url: /alertmanager
      fallback_config_file: /etc/mimir/alertmanager_fallback_config.yaml
    alertmanager_storage:
      s3:
        bucket_name: mimir-alertmanager


    memberlist:
      join_members: [ mimir-memberlist:7946 ]

    ingester:
      ring:
        replication_factor: 1

    store_gateway:
      sharding_ring:
        replication_factor: 1


    blocks_storage:
      s3:
        bucket_name: mimir-blocks
      tsdb:
        dir: /data/ingester
        ship_interval: 1m
        block_ranges_period: [ 2h ]
        retention_period: 3h
      bucket_store:
        index_cache:
          backend: memcached
          memcached:
            addresses: dns+memcached.memcached-system.svc:11211

        chunks_cache:
          backend: memcached
          memcached:
            addresses: dns+memcached.memcached-system.svc:11211

        metadata_cache:
          backend: memcached
          memcached:
            addresses: dns+memcached.memcached-system.svc:11211

    ruler:
      rule_path: /data/rules
      enable_api: true
      alertmanager_url: http://localhost:8080/alertmanager
    ruler_storage:
      s3:
        bucket_name: mimir-ruler
      cache:
        backend: memcached
        memcached:
          addresses: dns+memcached.memcached-system.svc:11211

    compactor:
      compaction_interval: 30s
      data_dir: /data/mimir-compactor
      cleanup_interval:    1m
      tenant_cleanup_delay: 1m

    limits:
      native_histograms_ingestion_enabled: true

    overrides_exporter:
      ring:
        enabled: true
        wait_stability_min_duration: 30s

    runtime_config:
      file: /etc/mimir/runtime.yaml
  runtime.yaml: |-
    # This file can be used to set overrides or other runtime config.
    ingester_limits: # limits that each ingester replica enforces
      max_ingestion_rate: 20000
      max_series: 1500000
      max_tenants: 1000
      max_inflight_push_requests: 30000

    distributor_limits: # limits that each distributor replica enforces
      max_ingestion_rate: 20000
      max_inflight_push_requests: 30000
      max_inflight_push_requests_bytes: 50000000

    overrides:
      anonymous: # limits for anonymous that the whole cluster enforces
        # ingestion_tenant_shard_size: 9
        max_global_series_per_user: 1500000
        max_fetched_series_per_query: 100000
        native_histograms_ingestion_enabled: true
        ruler_max_rules_per_rule_group: 50
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir-config-958c4gm5k9
  namespace: monitoring-system
---
apiVersion: v1
data:
  LOKI_S3_SECRET_ACCESS_KEY: VkQ1MzhPWXhTRWlHRDRJOW1tRmZxRk1DR3ExdklpR20=
kind: Secret
metadata:
  name: loki-env-58m52b99kc
  namespace: logging-system
type: Opaque
---
apiVersion: v1
data:
  memcached-address: bWVtY2FjaGVkLm1lbWNhY2hlZC1zeXN0ZW0uc3ZjLmNsdXN0ZXIubG9jYWw6MTEyMTE=
kind: Secret
metadata:
  name: alloy-integrations-memcached
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
data:
  mysql-host: bXlzcWwubXlzcWwtc3lzdGVtLnN2Yy5jbHVzdGVyLmxvY2Fs
  mysql-password: VkQ1MzhPWXhTRWlHRDRJOW1tRmZxRk1DR3ExdklpR20=
  mysql-username: bGd0bXA=
kind: Secret
metadata:
  name: alloy-integrations-mysql
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
data:
  redis-addr: cmVkaXMtbWFzdGVyLnJlZGlzLXN5c3RlbS5zdmMuY2x1c3Rlci5sb2NhbDo2Mzc5
  redis-password: VkQ1MzhPWXhTRWlHRDRJOW1tRmZxRk1DR3ExdklpR20=
kind: Secret
metadata:
  name: alloy-integrations-redis
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
data:
  MIMIR_S3_SECRET_ACCESS_KEY: VkQ1MzhPWXhTRWlHRDRJOW1tRmZxRk1DR3ExdklpR20=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir-env-92ddctt858
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: backend
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-backend
  namespace: logging-system
spec:
  ports:
  - name: http-metrics
    port: 3100
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: backend
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: backend
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
    prometheus.io/service-monitor: "false"
    variant: headless
  name: loki-backend-headless
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 3100
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: backend
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-memberlist
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: tcp
    port: 7946
    protocol: TCP
    targetPort: http-memberlist
  selector:
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: memberlist
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: backend
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
    prometheus.io/service-monitor: "false"
  name: loki-query-scheduler-discovery
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 3100
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: backend
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: read
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-read
  namespace: logging-system
spec:
  ports:
  - name: http-metrics
    port: 3100
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: read
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: read
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
    prometheus.io/service-monitor: "false"
    variant: headless
  name: loki-read-headless
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 3100
    protocol: TCP
    targetPort: http-metrics
  - appProtocol: tcp
    name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: read
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: write
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-write
  namespace: logging-system
spec:
  ports:
  - name: http-metrics
    port: 3100
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: write
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: write
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
    prometheus.io/service-monitor: "false"
    variant: headless
  name: loki-write-headless
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 3100
    protocol: TCP
    targetPort: http-metrics
  - appProtocol: tcp
    name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: write
    app.kubernetes.io/instance: loki
    app.kubernetes.io/name: loki
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: alloy
    app.kubernetes.io/version: v1.0.0
    helm.sh/chart: alloy-0.1.1
  name: alloy
  namespace: monitoring-system
spec:
  internalTrafficPolicy: Cluster
  ports:
  - name: http-metrics
    port: 12345
    protocol: TCP
    targetPort: 12345
  - name: grpc-otlp
    port: 4317
    protocol: TCP
    targetPort: 4317
  - name: http-otlp
    port: 4318
    protocol: TCP
    targetPort: 4318
  - name: zipkin
    port: 9411
    protocol: TCP
    targetPort: 9411
  - name: jaeger-compact
    port: 6831
    protocol: UDP
    targetPort: 6831
  selector:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/name: alloy
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: alloy
    app.kubernetes.io/version: v1.0.0
    helm.sh/chart: alloy-0.1.1
  name: alloy-cluster
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - name: http
    port: 12345
    protocol: TCP
    targetPort: 12345
  - name: grpc-otlp
    port: 4317
    protocol: TCP
    targetPort: 4317
  - name: http-otlp
    port: 4318
    protocol: TCP
    targetPort: 4318
  - name: zipkin
    port: 9411
    protocol: TCP
    targetPort: 9411
  - name: jaeger-compact
    port: 6831
    protocol: UDP
    targetPort: 6831
  selector:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/name: alloy
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
  - name: grpc-distribut
    port: 9095
  selector:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/name: mimir
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
    prometheus.io/service-monitor: "false"
  name: mimir-memberlist
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - appProtocol: tcp
    name: tcp-gossip-ring
    port: 7946
    protocol: TCP
    targetPort: 7946
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: read
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-read
  namespace: logging-system
spec:
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: read
      app.kubernetes.io/instance: loki
      app.kubernetes.io/name: loki
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  template:
    metadata:
      annotations:
        checksum/config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
      labels:
        app.kubernetes.io/component: read
        app.kubernetes.io/instance: loki
        app.kubernetes.io/name: loki
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: read
            topologyKey: kubernetes.io/hostname
      automountServiceAccountToken: true
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=read
        - -legacy-read-mode=false
        - -common.compactor-grpc-address=loki-backend.logging-system.svc.cluster.local:9095
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-env-58m52b99kc
        image: docker.io/grafana/loki:3.0.0
        imagePullPolicy: IfNotPresent
        name: loki
        ports:
        - containerPort: 3100
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 10
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /etc/loki/runtime-config
          name: runtime-config
        - mountPath: /tmp
          name: tmp
        - mountPath: /var/loki
          name: data
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki
      terminationGracePeriodSeconds: 30
      volumes:
      - emptyDir: {}
        name: tmp
      - emptyDir: {}
        name: data
      - configMap:
          items:
          - key: config.yaml
            path: config.yaml
          name: loki-config-t6t4f6hhcg
        name: config
      - configMap:
          name: loki-runtime
        name: runtime-config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.11.0
  name: mimir
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: mimir
      app.kubernetes.io/instance: mimir-monolithic-mode
      app.kubernetes.io/name: mimir
      app.kubernetes.io/part-of: memberlist
  template:
    metadata:
      annotations:
        logs.agent.grafana.com/scrape: "true"
        logs.agent.grafana.com/scrub-level: info
        profiles.grafana.com/cpu.port_name: http-metrics
        profiles.grafana.com/cpu.scrape: "false"
        profiles.grafana.com/goroutine.port_name: http-metrics
        profiles.grafana.com/goroutine.scrape: "false"
        profiles.grafana.com/memory.port_name: http-metrics
        profiles.grafana.com/memory.scrape: "false"
        pyroscope.io/service_name: mimir
      labels:
        app.kubernetes.io/component: mimir
        app.kubernetes.io/instance: mimir-monolithic-mode
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
    spec:
      containers:
      - args:
        - -target=all
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -memberlist.bind-addr=$(POD_IP)
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        envFrom:
        - secretRef:
            name: mimir-env-92ddctt858
        image: docker.io/grafana/mimir:2.11.0
        imagePullPolicy: IfNotPresent
        name: mimir
        ports:
        - containerPort: 8080
          name: http-metrics
        - containerPort: 9095
          name: grpc-distribut
        - containerPort: 7946
          name: http-memberlist
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
        resources:
          limits:
            cpu: 999m
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 55Mi
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /data
          name: storage
      terminationGracePeriodSeconds: 60
      volumes:
      - configMap:
          name: mimir-config-958c4gm5k9
        name: config
      - emptyDir: {}
        name: storage
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: backend
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-backend
  namespace: logging-system
spec:
  podManagementPolicy: Parallel
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: backend
      app.kubernetes.io/instance: loki
      app.kubernetes.io/name: loki
  serviceName: loki-backend-headless
  template:
    metadata:
      annotations:
        checksum/config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
      labels:
        app.kubernetes.io/component: backend
        app.kubernetes.io/instance: loki
        app.kubernetes.io/name: loki
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: backend
            topologyKey: kubernetes.io/hostname
      automountServiceAccountToken: true
      containers:
      - env:
        - name: METHOD
          value: WATCH
        - name: LABEL
          value: loki_rule
        - name: FOLDER
          value: /rules
        - name: RESOURCE
          value: both
        - name: WATCH_SERVER_TIMEOUT
          value: "60"
        - name: WATCH_CLIENT_TIMEOUT
          value: "60"
        - name: LOG_LEVEL
          value: INFO
        image: kiwigrid/k8s-sidecar:1.24.3
        imagePullPolicy: IfNotPresent
        name: loki-sc-rules
        volumeMounts:
        - mountPath: /rules
          name: sc-rules-volume
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=backend
        - -legacy-read-mode=false
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-env-58m52b99kc
        image: docker.io/grafana/loki:3.0.0
        imagePullPolicy: IfNotPresent
        name: loki
        ports:
        - containerPort: 3100
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 10
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /etc/loki/runtime-config
          name: runtime-config
        - mountPath: /tmp
          name: tmp
        - mountPath: /var/loki
          name: data
        - mountPath: /rules
          name: sc-rules-volume
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki
      terminationGracePeriodSeconds: 300
      volumes:
      - emptyDir: {}
        name: tmp
      - emptyDir: {}
        name: data
      - configMap:
          items:
          - key: config.yaml
            path: config.yaml
          name: loki-config-t6t4f6hhcg
        name: config
      - configMap:
          name: loki-runtime
        name: runtime-config
      - emptyDir: {}
        name: sc-rules-volume
  updateStrategy:
    rollingUpdate:
      partition: 0
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: write
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-write
  namespace: logging-system
spec:
  podManagementPolicy: Parallel
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: write
      app.kubernetes.io/instance: loki
      app.kubernetes.io/name: loki
  serviceName: loki-write-headless
  template:
    metadata:
      annotations:
        checksum/config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
      labels:
        app.kubernetes.io/component: write
        app.kubernetes.io/instance: loki
        app.kubernetes.io/name: loki
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: write
            topologyKey: kubernetes.io/hostname
      automountServiceAccountToken: true
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=write
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-env-58m52b99kc
        image: docker.io/grafana/loki:3.0.0
        imagePullPolicy: IfNotPresent
        name: loki
        ports:
        - containerPort: 3100
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 10
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /etc/loki/runtime-config
          name: runtime-config
        - mountPath: /var/loki
          name: data
      enableServiceLinks: true
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki
      terminationGracePeriodSeconds: 300
      volumes:
      - emptyDir: {}
        name: data
      - configMap:
          items:
          - key: config.yaml
            path: config.yaml
          name: loki-config-t6t4f6hhcg
        name: config
      - configMap:
          name: loki-runtime
        name: runtime-config
  updateStrategy:
    rollingUpdate:
      partition: 0
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: alloy
    app.kubernetes.io/version: v1.0.0
    helm.sh/chart: alloy-0.1.1
  name: alloy
  namespace: monitoring-system
spec:
  minReadySeconds: 10
  persistentVolumeClaimRetentionPolicy:
    whenDeleted: Delete
    whenScaled: Delete
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: alloy
      app.kubernetes.io/name: alloy
  serviceName: alloy
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: alloy
        logs.agent.grafana.com/scrape: "true"
        logs.agent.grafana.com/scrub-level: debug
        profiles.grafana.com/cpu.port_name: http-metrics
        profiles.grafana.com/cpu.scrape: "false"
        profiles.grafana.com/goroutine.port_name: http-metrics
        profiles.grafana.com/goroutine.scrape: "false"
        profiles.grafana.com/memory.port_name: http-metrics
        profiles.grafana.com/memory.scrape: "false"
        pyroscope.io/service_name: alloy
      labels:
        app.kubernetes.io/instance: alloy
        app.kubernetes.io/name: alloy
    spec:
      containers:
      - args:
        - run
        - /etc/alloy/config.alloy
        - --storage.path=/tmp/alloy
        - --server.http.listen-addr=0.0.0.0:12345
        - --server.http.ui-path-prefix=/
        - --disable-reporting
        - --cluster.enabled=true
        - --cluster.join-addresses=alloy-cluster
        - --stability.level=experimental
        env:
        - name: ALLOY_DEPLOY_MODE
          value: helm
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        envFrom:
        - secretRef:
            name: alloy-env
            optional: true
        image: docker.io/grafana/alloy:v1.0.0
        imagePullPolicy: IfNotPresent
        name: alloy
        ports:
        - containerPort: 12345
          name: http-metrics
        - containerPort: 4317
          name: grpc-otlp
          protocol: TCP
        - containerPort: 4318
          name: http-otlp
          protocol: TCP
        - containerPort: 9411
          name: zipkin
          protocol: TCP
        - containerPort: 6831
          name: jaeger-compact
          protocol: UDP
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 12345
            scheme: HTTP
          initialDelaySeconds: 10
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /etc/alloy
          name: config
        - mountPath: /etc/alloy/modules/kubernetes/metrics
          name: modules-kubernetes-metrics
        - mountPath: /etc/alloy/modules/kubernetes/integrations
          name: modules-kubernetes-integrations
        - mountPath: /etc/alloy/modules/kubernetes/logs
          name: modules-kubernetes-logs
        - mountPath: /etc/alloy/modules/kubernetes/traces
          name: modules-kubernetes-traces
        - mountPath: /etc/alloy/modules/kubernetes/profiles
          name: modules-kubernetes-profiles
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: alloy
      volumes:
      - configMap:
          name: alloy-config-8t9d8htff7
        name: config
      - configMap:
          name: alloy-modules-kubernetes-metrics-bgtb8d5hch
        name: modules-kubernetes-metrics
      - configMap:
          name: alloy-modules-kubernetes-integrations-2kb5k574d2
        name: modules-kubernetes-integrations
      - configMap:
          name: alloy-modules-kubernetes-logs-d7c756mt2f
        name: modules-kubernetes-logs
      - configMap:
          name: alloy-modules-kubernetes-traces-8mgm8th9m5
        name: modules-kubernetes-traces
      - configMap:
          name: alloy-modules-kubernetes-profiles-66c27bc84g
        name: modules-kubernetes-profiles
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: backend
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-backend
  namespace: logging-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: backend
      app.kubernetes.io/instance: loki
      app.kubernetes.io/name: loki
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: read
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-read
  namespace: logging-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: read
      app.kubernetes.io/instance: loki
      app.kubernetes.io/name: loki
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: write
    app.kubernetes.io/instance: loki
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki
    app.kubernetes.io/version: 3.0.0
    helm.sh/chart: loki-6.3.3
  name: loki-write
  namespace: logging-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: write
      app.kubernetes.io/instance: loki
      app.kubernetes.io/name: loki
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: alloy
    app.kubernetes.io/version: v1.0.0
    helm.sh/chart: alloy-0.1.1
  name: alloy
  namespace: monitoring-system
spec:
  endpoints:
  - honorLabels: true
    port: http-metrics
    scheme: http
  selector:
    matchLabels:
      app.kubernetes.io/instance: alloy
      app.kubernetes.io/name: alloy
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir
  namespace: monitoring-system
spec:
  endpoints:
  - port: http-metrics
    relabelings:
    - replacement: monitoring-system/mimir
      sourceLabels:
      - job
      targetLabel: job
    scheme: http
  namespaceSelector:
    matchNames:
    - monitoring-system
  selector:
    matchExpressions:
    - key: prometheus.io/service-monitor
      operator: NotIn
      values:
      - "false"
    matchLabels:
      app.kubernetes.io/component: mimir
      app.kubernetes.io/instance: mimir-monolithic-mode
      app.kubernetes.io/name: mimir
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  labels:
    app.kubernetes.io/instance: alloy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: alloy
    app.kubernetes.io/version: v1.0.0
    helm.sh/chart: alloy-0.1.1
  name: alloy
  namespace: monitoring-system
spec:
  rules:
  - host: alloy.localhost
    http:
      paths:
      - backend:
          service:
            name: alloy
            port:
              number: 12345
        path: /
        pathType: Prefix
