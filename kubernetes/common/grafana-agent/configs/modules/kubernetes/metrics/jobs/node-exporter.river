/*
Module: job-node-exporter
Description: Scrapes Node Exporter, this is a separate scrape job, if you are also using annotation based scraping, you will want to explicitly
             disable node-exporter from being scraped by this module and annotations by setting the following annotation on the node-exporter
             metrics.agent.grafana.com/scrape: "false".

             Node exporter should be deployed as a DaemonSet, each pod on each worker will be scraped by the agent using endpoint service discovery

Note: Every argument except for "forward_to" is optional, and does have a defined default value.  However, the values for these
      arguments are not defined using the default = " ... " argument syntax, but rather using the coalesce(argument.value, " ... ").
      This is because if the argument passed in from another consuming module is set to null, the default = " ... " syntax will
      does not override the value passed in, where coalesce() will return the first non-null value.
*/
argument "forward_to" {
	comment  = "Must be a list(MetricsReceiver) where collected logs should be forwarded to"
	optional = false
}

argument "enabled" {
	comment  = "Whether or not the node-exporter job should be enabled, this is useful for disabling the job when it is being consumed by other modules in a multi-tenancy environment (default: true)"
	optional = true
}

argument "namespaces" {
	comment  = "The namespaces to look for targets in (default: [] is all namespaces)"
	optional = true
}

argument "selectors" {
	// see: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
	comment  = "The label selectors to use to find matching targets (default: [\"app.kubernetes.io/name=prometheus-node-exporter\"])"
	optional = true
}

argument "port_name" {
	comment  = "The of the port to scrape metrics from (default: metrics)"
	optional = true
}

argument "job_label" {
	comment  = "The job label to add for all node-exporter metrics (default: integrations/node_exporter)"
	optional = true
}

argument "keep_metrics" {
	comment  = "A regex of metrics to keep (default: see below)"
	optional = true
}

argument "scrape_interval" {
	comment  = "How often to scrape metrics from the targets (default: 60s)"
	optional = true
}

argument "scrape_timeout" {
	comment  = "How long before a scrape times out (default: 10s)"
	optional = true
}

argument "max_cache_size" {
	comment  = "The maximum number of elements to hold in the relabeling cache (default: 100000).  This should be at least 2x-5x your largest scrape target or samples appended rate."
	optional = true
}

argument "clustering" {
	// Docs: https://grafana.com/docs/agent/latest/flow/concepts/clustering/
	comment  = "Whether or not clustering should be enabled (default: false)"
	optional = true
}

// node exporter service discovery for all of the pods in the node exporter daemonset
discovery.kubernetes "node_exporter" {
	role = "pod"

	selectors {
		role  = "pod"
		label = join(coalesce(argument.selectors.value, ["app.kubernetes.io/name=prometheus-node-exporter"]), ",")
	}

	namespaces {
		names = coalesce(argument.namespaces.value, [])
	}
}

// node exporter relabelings (pre-scrape)
discovery.relabel "node_exporter" {
	targets = discovery.kubernetes.node_exporter.targets

	// drop all targets if enabled is false
	rule {
		target_label = "__enabled"
		replacement  = format("%s", coalesce(argument.enabled.value, "true"))
	}

	rule {
		source_labels = ["__enabled"]
		regex         = "false"
		action        = "drop"
	}

	// keep only the specified metrics port name, and pods that are Running and ready
	rule {
		source_labels = [
			"__meta_kubernetes_pod_container_port_name",
			"__meta_kubernetes_pod_phase",
			"__meta_kubernetes_pod_ready",
		]
		separator = "@"
		regex     = coalesce(argument.port_name.value, "metrics") + "@Running@true"
		action    = "keep"
	}

	// copy the pod name to the instance label
	rule {
		source_labels = ["__meta_kubernetes_pod_node_name"]
		action        = "replace"
		target_label  = "instance"
	}
}

// node exporter scrape job
prometheus.scrape "node_exporter" {
	job_name        = coalesce(argument.job_label.value, "integrations/node_exporter")
	forward_to      = [prometheus.relabel.node_exporter.receiver]
	targets         = discovery.relabel.node_exporter.output
	scrape_interval = coalesce(argument.scrape_interval.value, "60s")
	scrape_timeout  = coalesce(argument.scrape_timeout.value, "10s")

	clustering {
		enabled = coalesce(argument.clustering.value, false)
	}
}

// node-exporter metric relabelings (post-scrape)
prometheus.relabel "node_exporter" {
	forward_to     = argument.forward_to.value
	max_cache_size = coalesce(argument.max_cache_size.value, 100000)

	// keep only metrics that match the keep_metrics regex
	rule {
		source_labels = ["__name__"]
		regex         = coalesce(argument.keep_metrics.value, "(up|node_cpu.*|node_exporter_build_info|node_filesystem.*|node_memory.*|process_cpu_seconds_total|process_resident_memory_bytes)")
		action        = "keep"
	}

	// Drop metrics for certain file systems
	rule {
		source_labels = ["__name__", "fstype"]
		separator     = "@"
		regex         = "node_filesystem.*@(tempfs)"
		action        = "drop"
	}
}
